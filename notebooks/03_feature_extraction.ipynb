{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Extraction for Software Requirements\n",
    "Dataset: processed clean text from 02_Preprocessing.ipynb\n",
    "\n",
    "Steps:\n",
    "1. Load preprocessed train/test data\n",
    "2. Extract TF-IDF features (bag-of-words com ngrams)\n",
    "3. Extract BERT embeddings (DistilBERT)\n",
    "4. Quick inspection of features\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "try:\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    ROOT = Path.cwd().parent\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from config import DATA_PROCESSED, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378e5e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4781, 3)\n",
      "Test shape: (1196, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "train_df = pd.read_csv(DATA_PROCESSED / \"train.csv\")\n",
    "test_df = pd.read_csv(DATA_PROCESSED / \"test.csv\")\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a81916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train shape: (4781, 5000)\n",
      "TF-IDF Test shape: (1196, 5000)\n",
      "Sample TF-IDF features: ['ability' 'ability create' 'ability modify' 'ability search'\n",
      " 'ability specify' 'ability view' 'able' 'able accept' 'able access'\n",
      " 'able acknowledge']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Feature Extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  \n",
    "    ngram_range=(1,2),  \n",
    ")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['clean_text'])\n",
    "\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"TF-IDF Train shape: {X_train_tfidf.shape}\")\n",
    "print(f\"TF-IDF Test shape: {X_test_tfidf.shape}\")\n",
    "print(\"Sample TF-IDF features:\", tfidf_vectorizer.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897ea04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Train embeddings shape: torch.Size([4781, 768])\n",
      "BERT Test embeddings shape: torch.Size([1196, 768])\n"
     ]
    }
   ],
   "source": [
    "# BERT Embeddings (DistilBERT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def get_bert_embeddings(text_list, batch_size=16):\n",
    "    \"\"\"\n",
    "    Returns mean-pooled BERT embeddings for a list of texts.\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "        enc = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**enc)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings)\n",
    "    return torch.cat(all_embeddings)\n",
    "\n",
    "\n",
    "X_train_bert = get_bert_embeddings(train_df['clean_text'].tolist())\n",
    "X_test_bert = get_bert_embeddings(test_df['clean_text'].tolist())\n",
    "\n",
    "print(f\"BERT Train embeddings shape: {X_train_bert.shape}\")\n",
    "print(f\"BERT Test embeddings shape: {X_test_bert.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884a62a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example TF-IDF vector (first training sample):\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Example BERT embedding (first training sample, first 10 values):\n",
      "[-0.04000298 -0.05843577  0.03065304  0.19102669  0.25054333 -0.16460642\n",
      "  0.02225917  0.18777972  0.05804351 -0.17780061]\n"
     ]
    }
   ],
   "source": [
    "# Quick inspection\n",
    "print(\"\\nExample TF-IDF vector (first training sample):\")\n",
    "print(X_train_tfidf[0].toarray())\n",
    "\n",
    "print(\"\\nExample BERT embedding (first training sample, first 10 values):\")\n",
    "print(X_train_bert[0].numpy()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25def9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample requirements:\n",
      " ['team member access maintain database server locally', 'system shall support multiple command line interface mode fastkramch bcturch muhturch madbtanam offer different functionality base user requirement', 'system shall able update user s location find mile radius', 'system shall deliver datum originator destination acceptable residual error rate ensure non corruption transfer datum', 'system shall assign default system datum value necessary']\n",
      "\n",
      "TF-IDF vectors (first sample):\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "BERT embedding (first sample, first 10 values):\n",
      "[-0.04000298 -0.05843577  0.03065304  0.19102669  0.25054333 -0.16460642\n",
      "  0.02225917  0.18777972  0.05804351 -0.17780061]\n"
     ]
    }
   ],
   "source": [
    "# Comparison: TF-IDF vs BERT (sample requirements)\n",
    "sample_texts = train_df['clean_text'].tolist()[:5]\n",
    "print(\"\\nSample requirements:\\n\", sample_texts)\n",
    "\n",
    "X_sample_tfidf = tfidf_vectorizer.transform(sample_texts)\n",
    "X_sample_bert = get_bert_embeddings(sample_texts)\n",
    "\n",
    "print(\"\\nTF-IDF vectors (first sample):\")\n",
    "print(X_sample_tfidf[0].toarray())\n",
    "\n",
    "print(\"\\nBERT embedding (first sample, first 10 values):\")\n",
    "print(X_sample_bert[0].numpy()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df6f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved TF-IDF and BERT features to /home/glaucia/RequirementsNLP/data/processed\n"
     ]
    }
   ],
   "source": [
    "# Save TF-IDF matrices\n",
    "np.save(DATA_PROCESSED / \"X_train_tfidf.npy\", X_train_tfidf.toarray())\n",
    "np.save(DATA_PROCESSED / \"X_test_tfidf.npy\", X_test_tfidf.toarray())\n",
    "\n",
    "# Save BERT embeddings\n",
    "np.save(DATA_PROCESSED / \"X_train_bert.npy\", X_train_bert.numpy())\n",
    "np.save(DATA_PROCESSED / \"X_test_bert.npy\", X_test_bert.numpy())\n",
    "\n",
    "print(f\"\\nSaved TF-IDF and BERT features to {DATA_PROCESSED}\")\n",
    "\n",
    "with open(MODELS_DIR / \"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_npl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
